import pandas as pd
import openai
import os
import json

# Configuraci√≥n
openai.api_key = os.getenv('OPENAI_API_KEY')

def load_messages_from_csv(csv_file):
    """Carga los mensajes desde un archivo CSV"""
    try:
        df = pd.read_csv('C:/Users/ASUS/Documents/Edson\Hackaton/adaptive-customer-service-mono/backend/app/m.csv')
        print(f"‚úì Archivo cargado: {len(df)} mensajes encontrados")
        print(f"Columnas disponibles: {list(df.columns)}\n")
        return df
    except Exception as e:
        print(f"Error al cargar el CSV: {e}")
        return None

def analyze_conversations_for_context(df):
    """
    Analiza conversaciones para extraer informaci√≥n contextual
    que ayudar√° a refinar el prompt del evaluador
    """
    
    # Agrupar mensajes por ticket_id
    ticket_ids = df['ticket_id'].dropna().unique()
    sample_size = min(15, len(ticket_ids))  # M√°ximo 15 conversaciones
    sample_tickets = ticket_ids[:sample_size]
    
    conversations_sample = []
    
    for ticket_id in sample_tickets:
        # Obtener mensajes del ticket ordenados por fecha
        ticket_messages = df[df['ticket_id'] == ticket_id].sort_values('created_at')
        
        conversation = []
        for _, row in ticket_messages.iterrows():
            role = "Asistente" if row.get('is_bot', False) else "Cliente"
            sender = row.get('sender_name', 'Desconocido')
            content = row['content']
            timestamp = row.get('created_at', '')
            
            conversation.append(f"[{timestamp}] {role} ({sender}): {content}")
        
        conversations_sample.append("\n".join(conversation))
    
    # Crear prompt para an√°lisis contextual
    conversations_text = "\n\n---NUEVA CONVERSACI√ìN---\n\n".join(conversations_sample)
    
    analysis_prompt = f"""Eres un experto en an√°lisis de conversaciones de servicio al cliente. 

Tu tarea es analizar las siguientes conversaciones entre clientes y asistentes de Kavak para extraer informaci√≥n cr√≠tica que ayudar√° a dise√±ar un sistema de evaluaci√≥n preciso.

CONVERSACIONES DE MUESTRA (Total: {len(conversations_sample)} conversaciones):
{conversations_text}

Por favor, analiza profundamente estas conversaciones y proporciona un an√°lisis estructurado en formato JSON con las siguientes secciones:

1. **CONTEXTO DEL NEGOCIO**:
   - ¬øQu√© tipo de negocio es Kavak? (industria, productos/servicios principales)
   - ¬øCu√°les son los casos de uso m√°s comunes en estas conversaciones?
   - ¬øQu√© procesos espec√≠ficos de Kavak se mencionan frecuentemente?

2. **CARACTER√çSTICAS DEL ASISTENTE**:
   - ¬øQu√© tono y estilo de comunicaci√≥n usa el asistente?
   - ¬øQu√© patrones de respuesta observas? (estructura, longitud, formalidad)
   - ¬øQu√© tipo de informaci√≥n t√©cnica maneja?
   - ¬øQu√© fortalezas destacan en las respuestas?
   - ¬øQu√© debilidades o √°reas de mejora identificas?

3. **PERFIL DEL CLIENTE**:
   - ¬øQu√© tipo de consultas hacen los clientes?
   - ¬øQu√© nivel de conocimiento t√©cnico demuestran?
   - ¬øQu√© emociones o urgencias expresan?
   - ¬øQu√© esperan obtener de la conversaci√≥n?

4. **PATRONES DE CONVERSACI√ìN**:
   - ¬øCu√°l es la estructura t√≠pica? (inicio, desarrollo, cierre)
   - ¬øCu√°ntos turnos suelen durar?
   - ¬øHay temas o problemas recurrentes?
   - ¬øQu√© informaci√≥n se pide/proporciona frecuentemente?

5. **ASPECTOS DE SEGURIDAD Y COMPLIANCE**:
   - ¬øQu√© pr√°cticas de seguridad de datos observas?
   - ¬øC√≥mo se maneja la informaci√≥n sensible?
   - ¬øQu√© procesos de verificaci√≥n (KYC) se mencionan?

6. **CRITERIOS DE CALIDAD ESPEC√çFICOS** (M√ÅS IMPORTANTE):
   - Bas√°ndote en estas conversaciones, identifica 7-10 criterios ESPEC√çFICOS para evaluar la calidad del asistente de Kavak
   - Para cada criterio:
     * Nombre descriptivo
     * Definici√≥n clara
     * Indicadores concretos de excelencia
     * Indicadores concretos de deficiencia
     * Peso/importancia relativa (1-10)

7. **CASOS EJEMPLARES**:
   - Identifica 3 ejemplos de respuestas EXCELENTES (cita el texto espec√≠fico y explica por qu√©)
   - Identifica 3 ejemplos de respuestas DEFICIENTES o que podr√≠an mejorar (cita y explica)

8. **CONTEXTO CULTURAL Y LING√ú√çSTICO**:
   - ¬øEn qu√© idioma(s) se comunican?
   - ¬øHay expresiones, modismos o formalismos espec√≠ficos?
   - ¬øQu√© nivel de formalidad es apropiado?

9. **RECOMENDACIONES PARA EL PROMPT DE EVALUACI√ìN**:
   - ¬øQu√© informaci√≥n espec√≠fica DEBE incluirse en el prompt del evaluador?
   - ¬øQu√© aspectos son CR√çTICOS y cu√°les menos relevantes?
   - ¬øQu√© sesgos o errores comunes debe evitar el evaluador?
   - ¬øQu√© contexto de Kavak es esencial para evaluar correctamente?

Proporciona tu an√°lisis en formato JSON v√°lido y estructurado."""

    try:
        print("üîç Analizando conversaciones para extraer contexto...\n")
        
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Eres un experto en an√°lisis conversacional y dise√±o de sistemas de evaluaci√≥n. Proporcionas an√°lisis profundos, espec√≠ficos y accionables en formato JSON."},
                {"role": "user", "content": analysis_prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        analysis = json.loads(response.choices[0].message.content)
        return analysis
    
    except Exception as e:
        print(f"Error al analizar conversaciones: {e}")
        return None

def generate_statistics(df):
    """Genera estad√≠sticas b√°sicas del dataset"""
    
    stats = {
        "total_mensajes": len(df),
        "total_tickets": df['ticket_id'].nunique(),
        "mensajes_promedio_por_ticket": len(df) / df['ticket_id'].nunique() if df['ticket_id'].nunique() > 0 else 0,
    }
    
    # Contar mensajes por rol
    if 'is_bot' in df.columns:
        stats['mensajes_bot'] = int(df['is_bot'].sum())
        stats['mensajes_cliente'] = int((~df['is_bot']).sum())
        stats['ratio_bot_cliente'] = stats['mensajes_bot'] / stats['mensajes_cliente'] if stats['mensajes_cliente'] > 0 else 0
    
    # Distribuci√≥n de longitud de mensajes
    df['content_length'] = df['content'].str.len()
    stats['longitud_promedio_mensaje'] = float(df['content_length'].mean())
    stats['longitud_promedio_bot'] = float(df[df['is_bot'] == True]['content_length'].mean())
    stats['longitud_promedio_cliente'] = float(df[df['is_bot'] == False]['content_length'].mean())
    
    # An√°lisis temporal
    df['created_at'] = pd.to_datetime(df['created_at'])
    stats['rango_fechas'] = {
        'inicio': str(df['created_at'].min()),
        'fin': str(df['created_at'].max())
    }
    
    return stats

def generate_refined_evaluation_prompt(context_analysis, stats):
    """
    Genera un prompt refinado para el evaluador basado en el an√°lisis contextual
    """
    
    prompt_template = f"""# PROMPT REFINADO PARA EVALUADOR DE CONVERSACIONES DE KAVAK

## CONTEXTO DEL NEGOCIO
{json.dumps(context_analysis.get('CONTEXTO_DEL_NEGOCIO', {}), indent=2, ensure_ascii=False)}

## CARACTER√çSTICAS DEL ASISTENTE IDEAL
{json.dumps(context_analysis.get('CARACTER√çSTICAS_DEL_ASISTENTE', {}), indent=2, ensure_ascii=False)}

## PERFIL T√çPICO DEL CLIENTE
{json.dumps(context_analysis.get('PERFIL_DEL_CLIENTE', {}), indent=2, ensure_ascii=False)}

## PATRONES DE CONVERSACI√ìN ESPERADOS
{json.dumps(context_analysis.get('PATRONES_DE_CONVERSACI√ìN', {}), indent=2, ensure_ascii=False)}

## ASPECTOS DE SEGURIDAD Y COMPLIANCE
{json.dumps(context_analysis.get('ASPECTOS_DE_SEGURIDAD_Y_COMPLIANCE', {}), indent=2, ensure_ascii=False)}

## ESTAD√çSTICAS DEL DATASET
- Total de conversaciones analizadas: {stats['total_tickets']}
- Mensajes promedio por conversaci√≥n: {stats['mensajes_promedio_por_ticket']:.1f}
- Ratio mensajes Bot/Cliente: {stats.get('ratio_bot_cliente', 'N/A'):.2f}
- Longitud promedio mensaje Bot: {stats.get('longitud_promedio_bot', 0):.0f} caracteres
- Longitud promedio mensaje Cliente: {stats.get('longitud_promedio_cliente', 0):.0f} caracteres

## CRITERIOS DE EVALUACI√ìN ESPEC√çFICOS PARA KAVAK
{json.dumps(context_analysis.get('CRITERIOS_DE_CALIDAD_ESPEC√çFICOS', {}), indent=2, ensure_ascii=False)}

## EJEMPLOS DE EXCELENCIA Y DEFICIENCIAS
{json.dumps(context_analysis.get('CASOS_EJEMPLARES', {}), indent=2, ensure_ascii=False)}

## CONTEXTO CULTURAL Y LING√ú√çSTICO
{json.dumps(context_analysis.get('CONTEXTO_CULTURAL_Y_LING√ú√çSTICO', {}), indent=2, ensure_ascii=False)}

## INSTRUCCIONES CR√çTICAS PARA EL EVALUADOR
{json.dumps(context_analysis.get('RECOMENDACIONES_PARA_EL_PROMPT_DE_EVALUACI√ìN', {}), indent=2, ensure_ascii=False)}

---

## PROMPT DE EVALUACI√ìN FINAL (LISTO PARA USAR)

Eres un evaluador experto de conversaciones de servicio al cliente de Kavak, empresa especializada en {context_analysis.get('contexto_del_negocio', {}).get('industria', 'compra-venta de autos')}.

**CONTEXTO CR√çTICO DE KAVAK:**
- Los asistentes deben manejar procesos complejos de inspecci√≥n, documentaci√≥n, KYC y pagos
- La seguridad de datos es CR√çTICA - nunca deben solicitarse datos sensibles por canales inseguros
- El tono debe ser profesional pero c√°lido, adapt√°ndose al cliente
- La claridad en tiempos, requisitos y procesos es fundamental

**TU TAREA:**
Analiza la siguiente conversaci√≥n entre un cliente y un asistente de Kavak.

[INSERTAR CONVERSACI√ìN AQU√ç]

**EVAL√öA LA CONVERSACI√ìN EN LOS SIGUIENTES CRITERIOS:**

{json.dumps(context_analysis.get('criterios_de_calidad_especificos', {}), indent=2, ensure_ascii=False)}

**FORMATO DE RESPUESTA:**
Para cada criterio proporciona:
1. **Puntuaci√≥n**: 1-10 (donde 10 es excelente)
2. **Justificaci√≥n**: Explicaci√≥n espec√≠fica con ejemplos de la conversaci√≥n
3. **Evidencia**: Citas textuales que respaldan tu evaluaci√≥n
4. **Recomendaciones**: 2-3 acciones concretas de mejora

**ESTRUCTURA JSON DE RESPUESTA:**
```json
{{
  "evaluaciones": {{
    "criterio_1": {{
      "puntuacion": X,
      "justificacion": "...",
      "evidencia": ["cita1", "cita2"],
      "recomendaciones": ["accion1", "accion2"]
    }},
    ...
  }},
  "puntuacion_general": X,
  "resumen_ejecutivo": "Resumen de 2-3 l√≠neas",
  "fortalezas_principales": ["fortaleza1", "fortaleza2", "fortaleza3"],
  "areas_criticas_de_mejora": ["mejora1", "mejora2", "mejora3"],
  "riesgo_compliance": "bajo/medio/alto con justificaci√≥n"
}}
```

**CONSIDERACIONES ESPECIALES:**
- S√© especialmente estricto con seguridad de datos y compliance
- Valora positivamente la empat√≠a sin sacrificar eficiencia
- Penaliza fuertemente solicitudes de datos sensibles por canales inseguros
- Considera el contexto del cliente (urgencia, frustraci√≥n, conocimiento t√©cnico)
"""
    
    return prompt_template

# Ejecuci√≥n principal
if __name__ == "__main__":
    print("="*80)
    print("EXTRACTOR DE CONTEXTO PARA REFINAMIENTO DE EVALUADOR LLM - KAVAK")
    print("="*80 + "\n")
    
    # 1. Cargar CSV
    csv_file = 'messages.csv'  # Cambia por la ruta de tu archivo
    df = load_messages_from_csv(csv_file)
    
    if df is None:
        print("‚ùå No se pudo cargar el archivo")
        exit()
    
    # 2. Generar estad√≠sticas b√°sicas
    print("üìä Generando estad√≠sticas del dataset...\n")
    stats = generate_statistics(df)
    print(json.dumps(stats, indent=2, ensure_ascii=False, default=str))
    print("\n")
    
    # 3. Analizar conversaciones para extraer contexto
    context_analysis = analyze_conversations_for_context(df)
    
    if context_analysis is None:
        print("‚ùå No se pudo completar el an√°lisis")
        exit()
    
    # 4. Guardar an√°lisis contextual completo
    output_file = 'contexto_para_evaluador_kavak.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'estadisticas': stats,
            'analisis_contextual': context_analysis
        }, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\n‚úì An√°lisis contextual guardado en '{output_file}'")
    
    # 5. Generar prompt refinado
    refined_prompt = generate_refined_evaluation_prompt(context_analysis, stats)
    
    prompt_file = 'prompt_evaluador_kavak_refinado.txt'
    with open(prompt_file, 'w', encoding='utf-8') as f:
        f.write(refined_prompt)
    
    print(f"‚úì Prompt refinado guardado en '{prompt_file}'")
    
    # 6. Mostrar resumen
    print("\n" + "="*80)
    print("RESUMEN DEL AN√ÅLISIS")
    print("="*80)
    print(json.dumps(context_analysis, indent=2, ensure_ascii=False))
    
    print("\n" + "="*80)
    print("‚úÖ PROCESO COMPLETADO")
    print("="*80)
    print("\nArchivos generados:")
    print(f"  1. {output_file} - An√°lisis contextual completo de Kavak")
    print(f"  2. {prompt_file} - Prompt refinado listo para evaluar conversaciones")
    print("\nüìã SIGUIENTE PASO:")
    print("  Usa el prompt refinado para evaluar nuevas conversaciones de Kavak")
    print("  con criterios espec√≠ficos extra√≠dos de tus datos reales.")