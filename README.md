# üéØ Adaptive Customer Service Mono

Sistema de atenci√≥n al cliente adaptativo e inteligente con capacidades de aprendizaje continuo mediante IA.

## üìã Descripci√≥n

**Adaptive Customer Service Mono** es un monorepo que implementa un sistema completo de servicio al cliente con inteligencia artificial adaptativa. El sistema se compone de tres m√≥dulos principales que trabajan en conjunto para proporcionar una experiencia de soporte optimizada y en constante mejora.

### Caracter√≠sticas Principales

- ü§ñ **Agente AI Inteligente**: Chatbot con IA capaz de responder dudas y gestionar tickets autom√°ticamente
- üìä **Panel de An√°lisis Adaptativo**: Dashboard de administraci√≥n con m√©tricas en tiempo real
- üîÑ **Aprendizaje Continuo**: El sistema analiza conversaciones activas y propone mejoras autom√°ticas
- üë• **Gesti√≥n de Usuarios**: Sistema completo de autenticaci√≥n y gesti√≥n de cuentas
- üé´ **Sistema de Tickets**: Creaci√≥n, seguimiento y resoluci√≥n de tickets de soporte
- üí¨ **Chat en Tiempo Real**: Comunicaci√≥n fluida entre clientes y el agente AI
- üìà **M√©tricas y Analytics**: An√°lisis detallado del rendimiento del chatbot

## üèóÔ∏è Arquitectura del Sistema

El proyecto est√° dividido en cuatro componentes principales:

```
adaptive-customer-service/
‚îú‚îÄ‚îÄ backend/              # API y l√≥gica de negocio
‚îú‚îÄ‚îÄ frontend/user/        # Interfaz de usuario para clientes
‚îú‚îÄ‚îÄ streamlit/            # Panel de administraci√≥n (Kavak Agentic Workbench)
‚îî‚îÄ‚îÄ notebook/             # An√°lisis y experimentaci√≥n con datos
```

## üîÑ C√≥mo Funciona el Sistema

### Flujo de Datos Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USUARIO FINAL                           ‚îÇ
‚îÇ  (Accede v√≠a Frontend Next.js - http://localhost:3000)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ 1. Login/Signup
               ‚îÇ 2. Crea ticket
               ‚îÇ 3. Inicia chat con AI
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      BACKEND (FastAPI)                          ‚îÇ
‚îÇ                   http://localhost:8000                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Autentica usuarios (JWT)                                     ‚îÇ
‚îÇ  ‚Ä¢ CRUD de tickets y mensajes                                   ‚îÇ
‚îÇ  ‚Ä¢ Integraci√≥n con OpenAI para respuestas del chatbot          ‚îÇ
‚îÇ  ‚Ä¢ Almacena conversaciones en PostgreSQL                        ‚îÇ
‚îÇ  ‚Ä¢ Calcula m√©tricas (CSAT, resolution rate, etc.)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ Exporta conversaciones
               ‚îÇ en formato JSONL
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              STREAMLIT - Agentic Workbench                      ‚îÇ
‚îÇ                   http://localhost:8501                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  FASE 1: An√°lisis                                               ‚îÇ
‚îÇ  ‚îú‚îÄ Carga JSONL de conversaciones                              ‚îÇ
‚îÇ  ‚îú‚îÄ Calcula m√©tricas baseline                                  ‚îÇ
‚îÇ  ‚îú‚îÄ Detecta intents autom√°ticamente                            ‚îÇ
‚îÇ  ‚îî‚îÄ Genera ranking de herramientas necesarias                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  FASE 2: Propuestas LLM                                         ‚îÇ
‚îÇ  ‚îú‚îÄ Env√≠a contexto completo a GPT-5-nano                       ‚îÇ
‚îÇ  ‚îú‚îÄ Recibe propuestas estructuradas:                           ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Mejoras de prompts                                      ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Cambios de c√≥digo                                       ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Tools a desarrollar                                     ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Plan de evaluaci√≥n                                      ‚îÇ
‚îÇ  ‚îÇ   ‚Ä¢ Assessment de riesgos                                   ‚îÇ
‚îÇ  ‚îî‚îÄ Administrador revisa y edita propuestas                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  FASE 3: Evaluaci√≥n                                             ‚îÇ
‚îÇ  ‚îú‚îÄ Administrador aprueba cambios                              ‚îÇ
‚îÇ  ‚îú‚îÄ Sistema regenera conversaciones con prompts mejorados      ‚îÇ
‚îÇ  ‚îú‚îÄ Generaci√≥n paralela (ThreadPoolExecutor)                   ‚îÇ
‚îÇ  ‚îú‚îÄ Compara baseline vs proposed                               ‚îÇ
‚îÇ  ‚îî‚îÄ Muestra deltas de m√©tricas                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  FASE 4: Implementaci√≥n                                         ‚îÇ
‚îÇ  ‚îú‚îÄ Descarga resultados (JSONL, CSV, JSON)                     ‚îÇ
‚îÇ  ‚îî‚îÄ Implementa mejoras en producci√≥n si hay mejora             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ Implementa mejoras aprobadas
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  BACKEND (Actualizado)                          ‚îÇ
‚îÇ  ‚Ä¢ Nuevos prompts aplicados                                     ‚îÇ
‚îÇ  ‚Ä¢ C√≥digo optimizado                                            ‚îÇ
‚îÇ  ‚Ä¢ Nuevas herramientas integradas                              ‚îÇ
‚îÇ  ‚Ä¢ Mejores respuestas del chatbot                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ Ciclo contin√∫a...
               ‚ñº
         [Nuevas conversaciones]
```

### Integraci√≥n Entre Componentes

#### Frontend ‚Üî Backend
```typescript
// Frontend hace request al backend
fetch('http://localhost:8000/api/tickets', {
  method: 'POST',
  headers: { 'Authorization': 'Bearer JWT_TOKEN' },
  body: JSON.stringify({ title, description })
})

// Backend responde con datos
response: { ticket_id, status, created_at }
```

#### Backend ‚Üî Database
```python
# Backend almacena en PostgreSQL
ticket = Ticket(
    user_id=current_user.id,
    title=ticket_data.title,
    description=ticket_data.description,
    status='open'
)
db.add(ticket)
db.commit()
```

#### Backend ‚Üí Streamlit (Exportaci√≥n)
```python
# Backend exporta conversaciones
conversations = db.query(Conversation).all()
with open('conversations.jsonl', 'w') as f:
    for conv in conversations:
        f.write(json.dumps(conv.to_dict()) + '\n')
```

#### Streamlit ‚Üî OpenAI
```python
# Streamlit consulta GPT-5-nano
response = client.chat.completions.create(
    model="gpt-5-nano-2025-08-07",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": analysis_context}
    ],
    temperature=0.8
)
```

### 1. Backend

El backend gestiona toda la l√≥gica de negocio del sistema:

- **Base de datos**: Almacenamiento persistente de usuarios, tickets y mensajes
- **API REST**: Endpoints para gesti√≥n de recursos
- **Autenticaci√≥n**: Sistema de login y gesti√≥n de sesiones
- **Integraci√≥n con IA**: Conexi√≥n con modelos de lenguaje para el chatbot
- **Gesti√≥n de Tickets**: CRUD completo de tickets de soporte
- **Gesti√≥n de Mensajes**: Almacenamiento y recuperaci√≥n de conversaciones

### 2. Frontend de Usuario (Next.js)

Interfaz web construida con Next.js para que los clientes interact√∫en con el sistema:

**Caracter√≠sticas:**
- **Portal de Usuario**: Dashboard personalizado con TypeScript y Tailwind CSS
- **Sistema de Login/Signup**: Autenticaci√≥n completa de usuarios
- **Vista de Tickets**: Interfaz para visualizar y gestionar tickets
- **Dashboard**: Panel principal con resumen de actividad
- **Chat en Vivo**: Componentes de chat para interactuar con el agente AI
- **Dise√±o Responsive**: Optimizado para dispositivos m√≥viles y desktop

**Estructura del Frontend:**
```
frontend/user/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ components/      # Componentes React reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/       # Vista principal del usuario
‚îÇ   ‚îú‚îÄ‚îÄ lib/            # Utilidades y helpers
‚îÇ   ‚îú‚îÄ‚îÄ login/          # P√°gina de inicio de sesi√≥n
‚îÇ   ‚îú‚îÄ‚îÄ signup/         # P√°gina de registro
‚îÇ   ‚îú‚îÄ‚îÄ tickets/        # Gesti√≥n de tickets
‚îÇ   ‚îú‚îÄ‚îÄ globals.css     # Estilos globales
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx      # Layout principal
‚îÇ   ‚îî‚îÄ‚îÄ page.tsx        # P√°gina de inicio
‚îú‚îÄ‚îÄ public/             # Recursos est√°ticos
‚îú‚îÄ‚îÄ .env.local          # Variables de entorno
‚îú‚îÄ‚îÄ package.json        # Dependencias
‚îú‚îÄ‚îÄ pnpm-lock.yaml      # Lockfile de pnpm
‚îú‚îÄ‚îÄ tailwind.config.ts  # Configuraci√≥n de Tailwind
‚îî‚îÄ‚îÄ tsconfig.json       # Configuraci√≥n de TypeScript
```

### 3. Panel de Administraci√≥n - Kavak Agentic Workbench (Streamlit)

Dashboard avanzado de an√°lisis y optimizaci√≥n continua del chatbot, construido con Streamlit y potenciado por **GPT-5-nano-2025-08-07**.

#### üéØ Caracter√≠sticas Principales

**1. An√°lisis de Conversaciones**
- **Carga de Datos**: Importa conversaciones en formato JSONL
- **M√©tricas Baseline**: Calcula autom√°ticamente:
  - Resolution Rate (tasa de resoluci√≥n)
  - CSAT promedio (Customer Satisfaction Score 1-5)
  - Promedio de turnos por conversaci√≥n
  - Duraci√≥n promedio de conversaciones
- **Visualizaci√≥n en Tiempo Real**: Dashboard con m√©tricas clave

**2. Sistema de Detecci√≥n de Intents**
El sistema identifica autom√°ticamente los intents de los usuarios mediante patrones regex:
- `offer_24h`: Ofertas de compra en 24 horas
- `status_eval`: Estado de evaluaci√≥n mec√°nica
- `payment_status`: Estatus de pagos y transferencias
- `reschedule_inspection`: Reprogramaci√≥n de inspecciones
- `credit_prequal`: Pre-calificaci√≥n de cr√©dito
- `warranty_claim`: Reclamaciones de garant√≠a
- `kyc_docs`: Recolecci√≥n de documentaci√≥n KYC
- `appointment`: Agendamiento de citas

**3. Ranking de Herramientas**
El sistema analiza las conversaciones y genera un ranking de herramientas (tools) que deber√≠an implementarse:
- **Esfuerzo estimado**: Clasificaci√≥n 1-3 seg√∫n complejidad
- **Frecuencia**: N√∫mero de veces que se necesit√≥ cada herramienta
- **Impacto**: Efecto esperado en las m√©tricas
- **Priorizaci√≥n**: Herramientas ordenadas por ROI potencial

Herramientas identificadas incluyen:
- OfferIn24 Orchestrator
- Inspection/Workshop Status Tracker
- Payout Status Tracker
- Inspection Re-Scheduler
- Credit Pre-Qualification Simulator
- Warranty Coverage Checker
- Doc & KYC Collector
- Scheduling Assistant

**4. Motor de Propuestas con LLM**
Al hacer clic en "Generar propuestas con LLM", el sistema:

a) **Analiza el contexto completo** de las conversaciones
b) **Identifica patrones** de √©xito y √°reas de mejora
c) **Genera propuestas** en 5 categor√≠as:

   **üìù Prompt Changes (Cambios de Prompts)**
   - **System Patch**: Mejoras al prompt del sistema
   - **User Patch**: Plantilla mejorada para mensajes de usuario
     - Soporta placeholders: `{contexto}`, `{tono}`, `{idioma}`, `{canal}`
   - **Rationale**: Explicaci√≥n detallada de por qu√© estos cambios mejorar√°n el sistema
   - **Editable**: Los administradores pueden modificar antes de aprobar

   **üíª Code Changes (Cambios de C√≥digo)**
   - Parches de c√≥digo sugeridos con:
     - T√≠tulo descriptivo
     - C√≥digo del patch
     - Impacto esperado
     - Nivel de riesgo

   **üîß Proposed Tools (Herramientas Propuestas)**
   - Lista de tools que deber√≠an desarrollarse:
     - Nombre de la herramienta
     - Justificaci√≥n (por qu√© es necesaria)
     - Esfuerzo estimado (1-3)
     - Sketch de la API

   **üìä Evaluation Plan (Plan de Evaluaci√≥n)**
   - **M√©tricas**: KPIs a monitorear
   - **Protocolo Offline**: C√≥mo evaluar sin usuarios reales
   - **Protocolo Online**: Plan de A/B testing en producci√≥n
   - **Criterios de √âxito**: Umbrales para considerar la mejora exitosa

   **‚ö†Ô∏è Risks (Riesgos)**
   - Lista de riesgos potenciales de implementar los cambios

**5. Sistema de Aprobaci√≥n y Aplicaci√≥n**
- **Edici√≥n de Prompts**: Modifica las propuestas del LLM antes de aplicarlas
- **Aprobaci√≥n**: Confirma qu√© cambios se implementar√°n
- **Configuraci√≥n de Evaluaci√≥n**: Define objetivos y pesos de m√©tricas:
  - Target CSAT objetivo (1.0-5.0)
  - M√°ximo de turnos objetivo
  - Latencia objetivo en segundos
  - Pesos personalizables para cada m√©trica:
    - Peso CSAT (0-1)
    - Peso Resolution Rate (0-1)
    - Peso Eficiencia de turnos (0-1)
    - Peso Latencia (0-1)

**6. Regeneraci√≥n y Evaluaci√≥n**
Una vez aprobados los prompts:
- **Generaci√≥n Paralela**: Regenera conversaciones usando ThreadPoolExecutor
  - Paralelismo configurable (1-16 workers)
  - Reintentos autom√°ticos por conversaci√≥n (1-8 intentos)
  - Control de temperatura del modelo (0.0-1.5)
- **Contextos m√∫ltiples**: Genera conversaciones para diferentes escenarios:
  - buying, ask, feedback, service, credit, warranty
- **Variaci√≥n de par√°metros**:
  - Tonos: amable, emp√°tico, formal, resolutivo, apolog√©tico, directo, entusiasta
  - Canales: WhatsApp, webchat, email, tel√©fono
  - Idiomas: espa√±ol, ingl√©s

**7. Comparativa Baseline vs Proposed**
El sistema genera un an√°lisis comparativo detallado:
- **M√©tricas lado a lado**
- **Deltas calculados**: Muestra mejoras o retrocesos
  - ‚ñ≤ Mejora
  - ‚ñº Deterioro
  - Ôºù Sin cambio
- **Visualizaci√≥n clara** de qu√© m√©tricas mejoraron

**8. Exportaci√≥n de Resultados**
Descarga m√∫ltiples formatos para an√°lisis externo:
- `llm_rewrite_response.json`: Propuestas completas del LLM
- `candidate_tools_ranked.csv`: Ranking de herramientas
- `baseline_conversations.jsonl`: Conversaciones originales
- `proposed_conversations.jsonl`: Conversaciones generadas con prompts mejorados
- `baseline_meta.csv`: Metadatos de conversaciones baseline
- `proposed_meta.csv`: Metadatos de conversaciones propuestas

#### ‚öôÔ∏è Configuraci√≥n del Panel

**Par√°metros Ajustables:**
```
- Conversaciones a regenerar por contexto: 1-10 (default: 3)
- Paralelismo (threads): 1-16 (default: 6)
- Reintentos por conversaci√≥n: 1-8 (default: 4)
- Temperature: 0.0-1.5 (default: 0.8)
- Target CSAT: 1.0-5.0 (default: 4.5)
- M√°x turnos objetivo: 2-12 (default: 6)
- Latencia objetivo: 10-600 seg (default: 120)
- Pesos de m√©tricas: 0.0-1.0 (personalizables)
```

#### üîê Autenticaci√≥n y Seguridad
- **API Key Management**: Lee credenciales desde `st.secrets` o variables de entorno
- **Modelo Fijo**: GPT-5-nano-2025-08-07 bloqueado por seguridad
- **Cach√© de Cliente**: OpenAI client cacheado con `@st.cache_resource`

#### üìà Flujo de Trabajo Completo

```mermaid
graph TD
    A[Subir JSONL] --> B[An√°lisis Autom√°tico]
    B --> C[Detecci√≥n de Intents]
    C --> D[Ranking de Tools]
    D --> E[Generar Propuestas LLM]
    E --> F[Revisar y Editar Prompts]
    F --> G[Aprobar Cambios]
    G --> H[Regenerar Dataset]
    H --> I[Comparar M√©tricas]
    I --> J{¬øMejora significativa?}
    J -->|S√≠| K[Exportar y Aplicar]
    J -->|No| F
    K --> L[Iterar]
    L --> A
```

**Estructura de Streamlit:**
```
streamlit/
‚îú‚îÄ‚îÄ app.py              # Aplicaci√≥n principal (595 l√≠neas)
‚îî‚îÄ‚îÄ requirements.txt    # Dependencias Python
```

**Tecnolog√≠as Utilizadas:**
- **Streamlit**: Framework de la interfaz
- **OpenAI GPT-5-nano**: Motor de propuestas
- **Pandas**: An√°lisis de datos
- **ThreadPoolExecutor**: Generaci√≥n paralela
- **Regex**: Detecci√≥n de intents
- **JSON/JSONL**: Formato de datos

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Backend
- **Framework**: FastAPI / Flask
- **Base de Datos**: PostgreSQL
- **ORM**: SQLAlchemy
- **IA**: OpenAI API (GPT-5-nano-2025-08-07)
- **Autenticaci√≥n**: JWT
- **Archivos**: 
  - `main.py`: Servidor principal
  - `models.py`: Modelos de BD
  - `schemas.py`: Validaci√≥n con Pydantic
  - `crud.py`: Operaciones de base de datos
  - `database.py`: Configuraci√≥n de conexi√≥n
  - `utils.py`: Utilidades
  - `kavak_metrics.py`: C√°lculo de m√©tricas
  - `Metrics.py`: M√©tricas adicionales
  - `prompt_training_LLMjudge.py`: Entrenamiento de prompts

### Frontend
- **Framework**: Next.js 14+ con App Router
- **Lenguaje**: TypeScript
- **UI Library**: Tailwind CSS
- **Package Manager**: pnpm
- **Estado**: React Context API / Hooks
- **HTTP Client**: Fetch API / Axios

### Panel de Administraci√≥n (Streamlit)
- **Framework**: Streamlit
- **LLM**: OpenAI GPT-5-nano-2025-08-07
- **An√°lisis de Datos**: Pandas, NumPy
- **Procesamiento**: 
  - Threading (ThreadPoolExecutor)
  - Regex para detecci√≥n de intents
  - JSON/JSONL para manejo de datos
- **Progreso**: stqdm (progress bars)
- **Configuraci√≥n**: python-dotenv

### Notebook
- **Jupyter Notebooks**: Para an√°lisis y experimentaci√≥n
- **Bibliotecas**: Pandas, NumPy, Matplotlib/Plotly

## üöÄ Instalaci√≥n

### Prerequisitos

- Node.js (v18+)
- pnpm (package manager recomendado) o npm
- Python (v3.9+)
- PostgreSQL
- API Key de OpenAI (para GPT-5-nano-2025-08-07)

### Clonar el Repositorio

```bash
git clone https://github.com/franciscodb/adaptive-customer-service-mono.git
cd adaptive-customer-service-mono
```

### Configuraci√≥n del Backend

```bash
cd backend

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Ejecutar migraciones
python manage.py migrate

# Iniciar servidor
python manage.py runserver
```

### Configuraci√≥n del Frontend

```bash
cd frontend/user

# Instalar dependencias con pnpm
pnpm install

# Configurar variables de entorno
cp .env.example .env.local
# Editar .env.local con la URL del backend

# Iniciar servidor de desarrollo
pnpm dev

# O con npm si prefieres
npm install
npm run dev
```

### Configuraci√≥n del Panel de Administraci√≥n (Streamlit)

```bash
cd streamlit

# Instalar dependencias
pip install -r requirements.txt

# Configurar secrets de Streamlit (recomendado)
mkdir -p .streamlit
# Crear .streamlit/secrets.toml con:
# openai_kavak_secret = "tu-api-key"

# O usar variables de entorno
export OPENAI_API_KEY=tu-api-key

# Iniciar aplicaci√≥n Streamlit
streamlit run app.py
```

## üìù Configuraci√≥n

### Variables de Entorno

#### Backend (.env)
```env
# Base de datos
DATABASE_URL=postgresql://user:password@localhost:5432/customer_service

# Seguridad
SECRET_KEY=your-secret-key-here

# OpenAI
OPENAI_API_KEY=sk-your-openai-key

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:8501

# Puerto (opcional, para Heroku)
PORT=8000
```

#### Frontend (.env.local)
```env
# URL del backend
NEXT_PUBLIC_API_URL=http://localhost:8000

# WebSockets (si aplica)
NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

#### Panel de Administraci√≥n Streamlit

**Opci√≥n 1: Streamlit Secrets (Recomendado)**

Crear `.streamlit/secrets.toml`:
```toml
openai_kavak_secret = "sk-your-openai-key"

# O alternativamente
OPENAI_API_KEY = "sk-your-openai-key"
```

**Opci√≥n 2: Variables de Entorno**
```env
OPENAI_API_KEY=sk-your-openai-key
openai_kavak_secret=sk-your-openai-key
```

> **Nota**: El modelo est√° fijado a `gpt-5-nano-2025-08-07` y no es configurable por seguridad.

## üíª Uso

### Para Usuarios (Clientes)

1. **Registro/Login**: Accede al frontend en `http://localhost:3000`
2. **Crear Ticket**: Navega a "Nuevo Ticket" y describe tu problema
3. **Chat con IA**: Inicia una conversaci√≥n con el agente AI
4. **Seguimiento**: Revisa el estado de tus tickets en el dashboard

### Para Administradores (Kavak Agentic Workbench)

1. **Acceder al Panel**: Abre `http://localhost:8501`

2. **Configurar Par√°metros**: En el sidebar, ajusta:
   - Conversaciones por contexto (1-10)
   - Paralelismo de threads (1-16)
   - Reintentos por conversaci√≥n (1-8)
   - Temperature del modelo (0.0-1.5)
   - Objetivos de evaluaci√≥n (CSAT, turnos, latencia)
   - Pesos de m√©tricas

3. **Cargar Conversaciones**:
   - Haz clic en "Sube el JSONL de conversaciones"
   - Selecciona tu archivo `.jsonl` con conversaciones hist√≥ricas
   - El sistema cargar√° y analizar√° autom√°ticamente

4. **Revisar M√©tricas Baseline**:
   - Ve las m√©tricas actuales del sistema:
     - Total de conversaciones
     - Resolution rate
     - CSAT promedio
     - Promedio de turnos
     - Duraci√≥n promedio

5. **Analizar Intents y Ranking**:
   - Revisa los intents detectados autom√°ticamente
   - Observa el ranking de herramientas sugeridas
   - Descarga `candidate_tools_ranked.csv` si deseas

6. **Generar Propuestas con LLM**:
   - Haz clic en "Generar propuestas con LLM"
   - Espera mientras GPT-5-nano analiza las conversaciones
   - Revisa las 5 categor√≠as de propuestas:
     - **Prompt changes**: Mejoras a los prompts del sistema
     - **Code changes**: Parches de c√≥digo sugeridos
     - **Proposed tools**: Herramientas a desarrollar
     - **Evaluation plan**: Plan de evaluaci√≥n detallado
     - **Risks**: Riesgos potenciales

7. **Editar y Aprobar Prompts**:
   - Modifica el `system_patch` si es necesario
   - Ajusta el `user_patch` (soporta placeholders)
   - Haz clic en "‚úÖ Aprobar estos prompts"

8. **Regenerar Dataset**:
   - Clic en "Regenerar dataset con prompts aprobados"
   - El sistema generar√° conversaciones nuevas usando los prompts mejorados
   - Proceso paralelo con m√∫ltiples workers

9. **Comparar Resultados**:
   - Revisa el comparativo Baseline vs Proposed
   - Observa los deltas (‚ñ≤ mejoras, ‚ñº retrocesos)
   - Analiza si las m√©tricas clave mejoraron:
     - Resolution rate
     - CSAT promedio
     - Eficiencia (turnos)
     - Duraci√≥n

10. **Exportar Resultados**:
    - Descarga los archivos generados:
      - `llm_rewrite_response.json`: Propuestas completas
      - `baseline_conversations.jsonl`: Conversaciones originales
      - `proposed_conversations.jsonl`: Conversaciones mejoradas
      - `baseline_meta.csv` y `proposed_meta.csv`: Metadatos

11. **Iterar**:
    - Si los resultados son buenos: implementa los cambios en producci√≥n
    - Si no son satisfactorios: ajusta par√°metros y repite desde el paso 6

### Flujo de Mejora Continua

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Subir conversaciones hist√≥ricas (JSONL)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Sistema analiza m√©tricas y detecta intents  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. LLM genera propuestas de mejora             ‚îÇ
‚îÇ    - Prompts optimizados                       ‚îÇ
‚îÇ    - C√≥digo sugerido                           ‚îÇ
‚îÇ    - Tools necesarias                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Admin revisa, edita y aprueba cambios       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Sistema regenera conversaciones con mejoras ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Comparar Baseline vs Proposed               ‚îÇ
‚îÇ    ¬øMejoraron las m√©tricas?                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ S√ç                         ‚îÇ NO
         ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7a. Implementar      ‚îÇ    ‚îÇ 7b. Ajustar          ‚îÇ
‚îÇ     en producci√≥n    ‚îÇ    ‚îÇ     par√°metros       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                                   ‚îî‚îÄ‚îÄ‚ñ∫ Repetir desde paso 3
```

## üìä Estructura del Proyecto

```
adaptive-customer-service/
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/              # Endpoints organizados por recurso
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/             # L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/          # Cache de Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crud.py               # Operaciones CRUD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py           # Configuraci√≥n de BD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kavak_metrics.py      # M√©tricas de Kavak
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Punto de entrada FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Metrics.py            # C√°lculo de m√©tricas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Modelos SQLAlchemy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_training_LLMjudge.py  # Entrenamiento de prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Esquemas Pydantic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.py              # Utilidades
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversations_meta (4).csv   # Dataset de conversaciones
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ m.csv                 # Datos adicionales
‚îÇ   ‚îú‚îÄ‚îÄ venv/                     # Entorno virtual Python
‚îÇ   ‚îú‚îÄ‚îÄ .env                      # Variables de entorno
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore
‚îÇ   ‚îú‚îÄ‚îÄ Procfile                  # Configuraci√≥n para Heroku
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ runtime.txt               # Versi√≥n de Python
‚îÇ   ‚îî‚îÄ‚îÄ test_connection.py        # Test de conexi√≥n a BD
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ user/
‚îÇ       ‚îú‚îÄ‚îÄ app/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ components/       # Componentes React reutilizables
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/        # Vista del dashboard
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ lib/              # Librer√≠as y utilidades
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ login/            # P√°gina de login
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ signup/           # P√°gina de registro
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tickets/          # Gesti√≥n de tickets
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ favicon.ico       # Favicon
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ globals.css       # Estilos globales
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx        # Layout principal
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx          # P√°gina de inicio
‚îÇ       ‚îú‚îÄ‚îÄ .next/                # Build de Next.js
‚îÇ       ‚îú‚îÄ‚îÄ .vercel/              # Configuraci√≥n de Vercel
‚îÇ       ‚îú‚îÄ‚îÄ node_modules/         # Dependencias Node
‚îÇ       ‚îú‚îÄ‚îÄ public/               # Archivos est√°ticos
‚îÇ       ‚îú‚îÄ‚îÄ .env.local            # Variables de entorno locales
‚îÇ       ‚îú‚îÄ‚îÄ .gitignore
‚îÇ       ‚îú‚îÄ‚îÄ eslint.config.mjs     # Configuraci√≥n ESLint
‚îÇ       ‚îú‚îÄ‚îÄ next-env.d.ts         # Tipos de Next.js
‚îÇ       ‚îú‚îÄ‚îÄ next.config.ts        # Configuraci√≥n de Next.js
‚îÇ       ‚îú‚îÄ‚îÄ package.json          # Dependencias del proyecto
‚îÇ       ‚îú‚îÄ‚îÄ pnpm-lock.yaml        # Lockfile de pnpm
‚îÇ       ‚îú‚îÄ‚îÄ postcss.config.mjs    # Configuraci√≥n PostCSS
‚îÇ       ‚îú‚îÄ‚îÄ README.md             # Documentaci√≥n del frontend
‚îÇ       ‚îú‚îÄ‚îÄ tailwind.config.ts    # Configuraci√≥n de Tailwind
‚îÇ       ‚îî‚îÄ‚îÄ tsconfig.json         # Configuraci√≥n TypeScript
‚îÇ
‚îú‚îÄ‚îÄ streamlit/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Kavak Agentic Workbench (595 l√≠neas)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt          # Dependencias: streamlit, openai, pandas, etc.
‚îÇ
‚îî‚îÄ‚îÄ notebook/                     # Jupyter notebooks para an√°lisis
    ‚îî‚îÄ‚îÄ [an√°lisis y experimentaci√≥n]
```

## üìÑ Formato de Datos JSONL

El panel de Streamlit trabaja con conversaciones en formato JSONL (JSON Lines). Cada l√≠nea representa una conversaci√≥n completa con la siguiente estructura:

### Estructura de una Conversaci√≥n

```json
{
  "conversation_id": "conv_12345",
  "meta": {
    "conversation_id": "conv_12345",
    "context": "buying",
    "tono": "emp√°tico",
    "canal": "whatsapp",
    "idioma": "es",
    "resolved": true,
    "num_interactions": 8,
    "duration_sec": 245,
    "timestamp": "2025-10-23T14:30:00Z"
  },
  "transcript": [
    {
      "role": "user",
      "content": "Hola, quiero informaci√≥n sobre la oferta de 24 horas",
      "timestamp": "2025-10-23T14:30:00Z"
    },
    {
      "role": "assistant",
      "content": "¬°Hola! Claro que s√≠, con gusto te ayudo...",
      "timestamp": "2025-10-23T14:30:15Z"
    }
  ],
  "outcomes": {
    "csat_estimated_1_5": 4.5,
    "summary": "Cliente consult√≥ sobre oferta 24h y recibi√≥ informaci√≥n completa",
    "intent_detected": ["offer_24h"],
    "tools_needed": ["OfferIn24 Orchestrator"],
    "resolution_reason": "Cliente satisfecho con la informaci√≥n proporcionada"
  }
}
```

### Campos Principales

#### `meta` (Metadatos)
- **conversation_id**: Identificador √∫nico de la conversaci√≥n
- **context**: Contexto de la conversaci√≥n (`buying`, `ask`, `feedback`, `service`, `credit`, `warranty`)
- **tono**: Tono usado (`amable`, `emp√°tico`, `formal`, `resolutivo`, `apolog√©tico`, `directo`, `entusiasta`)
- **canal**: Canal de comunicaci√≥n (`whatsapp`, `webchat`, `email`, `telefono`)
- **idioma**: Idioma de la conversaci√≥n (`es`, `en`)
- **resolved**: Boolean indicando si el problema se resolvi√≥
- **num_interactions**: N√∫mero total de mensajes en la conversaci√≥n
- **duration_sec**: Duraci√≥n en segundos

#### `transcript` (Transcripci√≥n)
Array de mensajes con:
- **role**: `user` o `assistant`
- **content**: Contenido del mensaje
- **timestamp**: Marca de tiempo del mensaje

#### `outcomes` (Resultados)
- **csat_estimated_1_5**: CSAT estimado (1-5)
- **summary**: Resumen de la conversaci√≥n
- **intent_detected**: Lista de intents detectados
- **tools_needed**: Herramientas que hubieran sido √∫tiles
- **resolution_reason**: Raz√≥n de la resoluci√≥n o no resoluci√≥n

### Ejemplo de Archivo JSONL

```jsonl
{"conversation_id": "conv_001", "meta": {...}, "transcript": [...], "outcomes": {...}}
{"conversation_id": "conv_002", "meta": {...}, "transcript": [...], "outcomes": {...}}
{"conversation_id": "conv_003", "meta": {...}, "transcript": [...], "outcomes": {...}}
```

> **Nota**: Cada l√≠nea del archivo JSONL es un JSON v√°lido independiente.

## üîë Caracter√≠sticas Destacadas

### Sistema de Aprendizaje Adaptativo Impulsado por LLM

El verdadero diferenciador del sistema es su **motor de optimizaci√≥n continua basado en GPT-5-nano**:

#### üß† An√°lisis Inteligente de Conversaciones
- **Detecci√≥n Autom√°tica de Intents**: Identifica 8 categor√≠as de intents mediante regex patterns
- **Scoring Compuesto**: Calcula puntuaciones ponderadas basadas en:
  - CSAT (Customer Satisfaction Score)
  - Resolution Rate
  - Eficiencia de turnos
  - Latencia de respuesta
- **Ranking Din√°mico**: Prioriza herramientas seg√∫n frecuencia, esfuerzo e impacto

#### ü§ñ Generaci√≥n de Propuestas con LLM
El sistema env√≠a el contexto completo al LLM y recibe propuestas estructuradas en 5 dimensiones:

1. **Prompt Engineering**
   - Mejoras al system prompt
   - Templates optimizados con placeholders din√°micos
   - Rationale detallado de cada cambio

2. **Code Optimization**
   - Parches de c√≥digo sugeridos
   - An√°lisis de impacto y riesgo
   - Mejoras de rendimiento

3. **Tool Discovery**
   - Identifica herramientas necesarias
   - API sketches para implementaci√≥n
   - Estimaci√≥n de esfuerzo (1-3)

4. **Evaluation Framework**
   - M√©tricas a monitorear
   - Protocolos offline y online
   - Criterios de √©xito cuantificables

5. **Risk Assessment**
   - Identificaci√≥n de riesgos potenciales
   - Estrategias de mitigaci√≥n

#### üîÑ Ciclo de Mejora Continua
```
Conversaciones ‚Üí An√°lisis LLM ‚Üí Propuestas ‚Üí Aprobaci√≥n ‚Üí 
Regeneraci√≥n ‚Üí Evaluaci√≥n ‚Üí ¬øMejora? ‚Üí Implementaci√≥n/Iteraci√≥n
```

#### ‚ö° Generaci√≥n Paralela Optimizada
- **ThreadPoolExecutor**: Procesa m√∫ltiples conversaciones simult√°neamente
- **Reintentos Inteligentes**: Manejo robusto de errores con backoff exponencial
- **Seeds Reproducibles**: Generaci√≥n determinista para comparaciones justas
- **Progress Tracking**: Barras de progreso con stqdm

### M√©tricas Disponibles en el Sistema

#### M√©tricas de Rendimiento
- **CSAT (Customer Satisfaction Score)**: Estimaci√≥n 1-5 basada en an√°lisis del LLM
- **Resolution Rate**: Porcentaje de problemas resueltos exitosamente
- **Average Turns**: N√∫mero promedio de interacciones por conversaci√≥n
- **Average Duration**: Duraci√≥n promedio en segundos
- **Latency**: Tiempo de respuesta del sistema

#### M√©tricas de Intents
- **Frecuencia por Intent**: Conteo de cada intent detectado
- **Tools Needed**: Herramientas requeridas por intent
- **Effort Score**: Complejidad estimada de implementaci√≥n
- **Priority Score**: Ranking basado en impacto vs esfuerzo

#### M√©tricas Compuestas
- **Composite Score**: Puntuaci√≥n ponderada global
  - Formula: `(CSAT_norm √ó w_csat) + (res_rate √ó w_res) + (turn_eff √ó w_turns) + (lat_eff √ó w_lat)`
- **Improvement Delta**: Diferencia entre baseline y proposed
- **ROI Estimado**: Retorno esperado de implementar mejoras

### Configurabilidad Total

**Pesos de M√©tricas Personalizables:**
- CSAT Weight: 0.0 - 1.0 (default: 0.35)
- Resolution Rate Weight: 0.0 - 1.0 (default: 0.35)
- Efficiency Weight: 0.0 - 1.0 (default: 0.15)
- Latency Weight: 0.0 - 1.0 (default: 0.15)

**Objetivos Ajustables:**
- Target CSAT: 1.0 - 5.0
- Max Turns Target: 2 - 12
- Latency Target: 10 - 600 segundos

**Par√°metros de Generaci√≥n:**
- Conversations per Context: 1 - 10
- Thread Parallelism: 1 - 16
- Max Retry Attempts: 1 - 8
- Temperature: 0.0 - 1.5

## üß™ Testing

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test

# Admin panel tests
cd admin-panel
pytest tests/
```

## ü§ù Contribuci√≥n

¬°Las contribuciones son bienvenidas! Por favor sigue estos pasos:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Gu√≠as de Contribuci√≥n

- Sigue las convenciones de c√≥digo del proyecto
- Escribe tests para nuevas funcionalidades
- Actualiza la documentaci√≥n seg√∫n sea necesario
- Aseg√∫rate de que todos los tests pasen antes de hacer PR

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üë• Autores

- **Francisco DB** - *Trabajo Inicial* - [@franciscodb](https://github.com/franciscodb)

## üôè Agradecimientos

- Comunidad de OpenAI/Anthropic por las APIs de IA
- Streamlit por facilitar la creaci√≥n de dashboards interactivos
- Todos los contribuidores que han participado en este proyecto

## üìû Soporte

Si tienes alguna pregunta o problema:

- üìß Email: soporte@example.com
- üêõ Issues: [GitHub Issues](https://github.com/franciscodb/adaptive-customer-service-mono/issues)
- üí¨ Discusiones: [GitHub Discussions](https://github.com/franciscodb/adaptive-customer-service-mono/discussions)

## üó∫Ô∏è Roadmap

### En Desarrollo
- [ ] Implementaci√≥n de las 8 herramientas prioritarias detectadas
  - [ ] OfferIn24 Orchestrator
  - [ ] Inspection/Workshop Status Tracker
  - [ ] Payout Status Tracker
  - [ ] Credit Pre-Qualification Simulator
  - [ ] Warranty Coverage Checker
  - [ ] Inspection Re-Scheduler
  - [ ] Doc & KYC Collector
  - [ ] Scheduling Assistant

### Pr√≥ximas Mejoras
- [ ] A/B Testing Framework integrado
- [ ] Monitoreo de conversaciones en tiempo real
- [ ] Auto-aplicaci√≥n de mejoras aprobadas
- [ ] Detecci√≥n de nuevos intents autom√°ticamente
- [ ] Exportaci√≥n de m√©tricas a BI tools (Power BI, Tableau)
- [ ] Integraci√≥n con m√∫ltiples modelos LLM (Claude, Gemini)
- [ ] Sistema de rollback autom√°tico si las m√©tricas empeoran

### Futuras Funcionalidades
- [ ] Soporte multiidioma (ingl√©s, portugu√©s)
- [ ] Integraci√≥n con WhatsApp Business API
- [ ] Integraci√≥n con Telegram
- [ ] Sistema de transcripci√≥n de llamadas telef√≥nicas
- [ ] Dashboard ejecutivo con reportes autom√°ticos
- [ ] API p√∫blica para integraciones externas
- [ ] Modo offline para el chatbot
- [ ] Sistema de versionado de prompts
- [ ] Auditor√≠a completa de cambios
- [ ] Simulador de conversaciones antes de deployar

---

‚≠êÔ∏è Si este proyecto te ha sido √∫til, por favor considera darle una estrella en GitHub
